Index: src/main/scala/org/data_training/engine/Engine.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/engine/Engine.scala b/src/main/scala/org/data_training/engine/Engine.scala
--- a/src/main/scala/org/data_training/engine/Engine.scala	
+++ b/src/main/scala/org/data_training/engine/Engine.scala	
@@ -11,10 +11,10 @@
     val spark = SparkSession.builder()
       .master("spark://spark-master-0.spark-headless.spark.svc.cluster.local:7077")
       .appName("ETL_Training")
-      .config("spark.sql.warehouse.dir", "hdfs://192.168.182.17:8020/hive/warehouse")
-      .config("hive.metastore.warehouse.dir", "hdfs://192.168.182.17:8020/hive/warehouse")
+      .config("spark.sql.warehouse.dir", "hdfs://192.168.182.6:8020/hive/warehouse")
+      .config("hive.metastore.warehouse.dir", "hdfs://192.168.182.6:8020/hive/warehouse")
       //.config("mapreduce.fileoutputcommitter.marksuccessfuljobs", "false")
-      .config("hive.metastore.uris", "thrift://192.168.219.111:9850")
+      .config("hive.metastore.uris", "thrift://192.168.219.114:9850")
       .enableHiveSupport()
       .getOrCreate();
     spark
Index: src/main/scala/org/data_training/engine/Constant.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/engine/Constant.scala b/src/main/scala/org/data_training/engine/Constant.scala
--- a/src/main/scala/org/data_training/engine/Constant.scala	
+++ b/src/main/scala/org/data_training/engine/Constant.scala	
@@ -2,6 +2,6 @@
 
 trait Constant {
 
-  val JobsList : List[String] = List("Customers")
+  val JobsList : List[String] = List("Hdfs_into_postgres","Customers","CustomerMasterData")
 
 }
Index: src/main/scala/org/data_training/jobs/Customers.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Customers.scala b/src/main/scala/org/data_training/jobs/Customers.scala
--- a/src/main/scala/org/data_training/jobs/Customers.scala	
+++ b/src/main/scala/org/data_training/jobs/Customers.scala	
@@ -1,8 +1,8 @@
 package org.data_training.jobs
 
 import org.data_training.Runnable
-import org.apache.spark.sql.functions.{current_timestamp, date_format}
-import org.apache.spark.sql.{DataFrame, SparkSession}
+import org.apache.spark.sql.functions.{current_timestamp, date_format, regexp_replace}
+import org.apache.spark.sql.{DataFrame, SparkSession, types}
 import org.data_training.Runnable
 import org.data_training.engine.Engine
 
@@ -10,28 +10,48 @@
 
 var customers_DF: DataFrame = _
 
-  def run (spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run (spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
+    import spark.implicits._
   print ("############## starting Customers JOB ##############")
+    val schema = types.StructType(Array(
+      types.StructField("id", types.StringType, true),
+      types.StructField("uniqueId", types.StringType, true),
+      types.StructField("zipCode", types.StringType, true),
+      types.StructField("city", types.StringType, true),
+      types.StructField("state", types.StringType, true),
+    ))
+   val df =spark.sql("SELECT * FROM ecom1.customers_dataset ")
+
+    customers_DF= spark.createDataFrame(df.rdd, schema=schema)
+    customers_DF.columns.foreach(col_name => {
+      customers_DF=customers_DF.withColumn(col_name,regexp_replace(customers_DF(col_name),"\"",""))
+    })
+    println(customers_DF.show(10))
 
-  customers_DF = spark.sql ("SELECT * FROM ecom.customers_dataset ")
 
-  print ("############## processing customers JOB ##############")
+  //customers_DF = spark.sql ("SELECT * FROM ecom.customers_dataset ")
+
+
+  println ("############## processing customers JOB ##############")
 
-  val result = process ()
+    val result = process ()
 
-  print ("############## writing customers JOB ##############")
 
-  result.coalesce(1).write.option("delimiter", ",").csv ("hdfs://192.168.182.17:8020/hive/warehouse/processEcomData/customers_dataset_final")
+    println ("############## writing customers JOB ##############")
+  println(result.show(4))
+  result.coalesce(1).write.option("header","true").option("delimiter", ",").csv ("hdfs://192.168.182.6:8020/hive/warehouse/processEcomData/customers_dataset_final")
 
-  print ("##############  Customers JOB Finished ###s###########")
-    print(s"working dir: ${System.getProperty("user.dir")}")
+  println ("##############  Customers JOB Finished ###s###########")
+    //print(s"working dir: ${System.getProperty("user.dir")}")
   }
 
   def process () = {
 
-  customers_DF.withColumn ("insertion_date", date_format (current_timestamp (), "yyyy-MM-dd") )
+
+
+
+    customers_DF.withColumn ("insertion_date", date_format (current_timestamp (), "yyyy-MM-dd") )
 
-
   }
 
   def JobsName2Log (): String = {
Index: src/main/scala/org/data_training/Runnable.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/Runnable.scala b/src/main/scala/org/data_training/Runnable.scala
--- a/src/main/scala/org/data_training/Runnable.scala	
+++ b/src/main/scala/org/data_training/Runnable.scala	
@@ -5,7 +5,7 @@
 
 trait Runnable extends Constant{
 
- def run (spark : SparkSession, odate : String, engine: Engine )
+ def run (spark : SparkSession, odate : String, engine: Engine , args: String*)
  def JobsName2Log(): String
 
 }
Index: src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala b/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala
--- a/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala	
+++ b/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala	
@@ -1,6 +1,62 @@
 package org.data_training.jobs
 
-class Hdfs_into_postgres {
+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession,types}
+import org.data_training.Runnable
+import org.data_training.engine.Engine
+
+
+import java.util.Properties
+
+case class Hdfs_into_postgres() extends Runnable{
+
+
+  def run(spark: SparkSession, odate: String, engine: Engine, args: String*): Unit = {
+
+    val schema=types.StructType(Array(
+      types.StructField("id",types.StringType,true),
+      types.StructField("uniqueId",types.StringType,true),
+      types.StructField("zipCode",types.StringType,true),
+      types.StructField("city",types.StringType,true),
+      types.StructField("state",types.StringType,true),
+    ))
+
+    val customers_df = spark.read.format("csv")
+      .option("delimiter", ",")
+      .option("header", "false")
+      .schema(schema)
+      .option("encoding", "utf-8")
+      .load(args(0))
+    println ("############## starting Hdfs_into_postgres JOB ##############")
+    println(args(0))
+    println(customers_df.printSchema())
+    println(customers_df.show(4))
+    //Get All column names from DataFrame val allColumnNames=df.columns
+    println(customers_df.columns.mkString("|*|"))
+    println("##############  Hdfs_into_postgres JOB Finished ###s###########")
+
+  }
+
+
+  def JobsName2Log(): String = {
+    "Hdfs_into_postgres"
+  }
+
+
+  /*def writeToPostgreSQL(postgres_url: String, spark_session: SparkSession, username_df: DataFrame): Unit = {
+
+    val connection_props = new Properties()
+    connection_props.setProperty("driver", "org.postgresql.Driver")
+    connection_props.setProperty("user", "postgres")
+    connection_props.setProperty("password", "postgres")
+
+    val table_name = "public.Username"
+
+    //Passing in the URL, table in which data will be written and relevant connection properties
+    username_df.write.mode(SaveMode.Append).jdbc(postgres_url, table_name, connection_props)
+
+  }*/
+
+
 
 
 
Index: src/main/scala/org/data_training/App.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/App.scala b/src/main/scala/org/data_training/App.scala
--- a/src/main/scala/org/data_training/App.scala	
+++ b/src/main/scala/org/data_training/App.scala	
@@ -19,12 +19,15 @@
     val spark = engine.init_spark()
 
     val JobsNames = args(0)
+    val file_location =  args(1)
+
 
     val JobsToBeExecuted = getJobsFromInput(JobsNames)
     JobsToBeExecuted.foreach{ runnableJOB =>
       try{
         //runnableJOB.JobsName2Log() = JobsNames
-        runnableJOB.run(spark,"",engine)
+        runnableJOB.run(spark,"",engine,file_location)
+
       }catch{
         case exception : Exception => print(" Job "+ runnableJOB.JobsName2Log()+ " failed. /n" + exception)
       }
@@ -36,7 +39,7 @@
 
    def getJobsFromInput(inputargs: String): List[Runnable] ={
      val ETL_JobsList = ListBuffer[Runnable]()
-    JobsList.foreach(item => {
+    JobsList.filter(_==inputargs).foreach(item => {
 
       val runClass = Class.forName("org.data_training.jobs."+item).newInstance().asInstanceOf[Runnable]
       ETL_JobsList += runClass
Index: src/main/scala/org/data_training/jobs/Order_payments.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Order_payments.scala b/src/main/scala/org/data_training/jobs/Order_payments.scala
--- a/src/main/scala/org/data_training/jobs/Order_payments.scala	
+++ b/src/main/scala/org/data_training/jobs/Order_payments.scala	
@@ -9,7 +9,7 @@
 
   var order_payments_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Order_payments JOB ##############")
 
     order_payments_DF = spark.sql("SELECT * FROM order_payments_dataset ")
Index: src/main/scala/org/data_training/jobs/Orders.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Orders.scala b/src/main/scala/org/data_training/jobs/Orders.scala
--- a/src/main/scala/org/data_training/jobs/Orders.scala	
+++ b/src/main/scala/org/data_training/jobs/Orders.scala	
@@ -9,7 +9,7 @@
 
   var orders_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Orders JOB ##############")
 
     orders_DF = spark.sql("SELECT * FROM orders_dataset ")
Index: src/main/scala/org/data_training/jobs/Products.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Products.scala b/src/main/scala/org/data_training/jobs/Products.scala
--- a/src/main/scala/org/data_training/jobs/Products.scala	
+++ b/src/main/scala/org/data_training/jobs/Products.scala	
@@ -9,7 +9,7 @@
 
   var product_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Products JOB ##############")
 
     product_DF = spark.sql("SELECT * FROM products_dataset ")
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	
+++ b/.idea/workspace.xml	
@@ -4,48 +4,23 @@
     <option name="autoReloadType" value="SELECTIVE" />
   </component>
   <component name="ChangeListManager">
-    <list default="true" id="7ffb4202-2b2c-4c82-884d-04284ffcf36c" name="Changes" comment="New jobs">
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/codeStyles/Project.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/codeStyles/codeStyleConfig.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/compiler.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/encodings.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/jarRepositories.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/misc.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/scala_compiler.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/vcs.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/.idea/workspace.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/pom.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/src/main/scala/org/example/App.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/src/test/scala/samples/junit.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/src/test/scala/samples/scalatest.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../Hive/src/test/scala/samples/specs.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/mariadb.iml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/pom.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/src/main/scala/org/example/App.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/src/test/scala/samples/junit.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/src/test/scala/samples/scalatest.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../mariadb/src/test/scala/samples/specs.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/.gitignore" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/codeStyles/Project.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/codeStyles/codeStyleConfig.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/compiler.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/encodings.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/jarRepositories.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/misc.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/scala_compiler.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/.idea/vcs.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/pom.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/src/main/scala/org/example/App.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/src/test/scala/samples/junit.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/src/test/scala/samples/scalatest.scala" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/../sparkHive/src/test/scala/samples/specs.scala" afterDir="false" />
+    <list default="true" id="7ffb4202-2b2c-4c82-884d-04284ffcf36c" name="Changes" comment=" store the output in hdfs">
+      <change beforePath="$PROJECT_DIR$/../Hive/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/../Hive/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/pom.xml" beforeDir="false" afterPath="$PROJECT_DIR$/pom.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/App.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/App.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/Runnable.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/Runnable.scala" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/engine/Constant.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/engine/Constant.scala" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/engine/Engine.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/engine/Engine.scala" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Customers.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Customers.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Geolocation.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Geolocation.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Hdfs_into_postgres.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_items.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_items.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_payments.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_payments.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_reviews.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Order_reviews.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Orders.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Orders.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Products.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Products.scala" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Sellers.scala" beforeDir="false" afterPath="$PROJECT_DIR$/src/main/scala/org/data_training/jobs/Sellers.scala" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -84,7 +59,7 @@
   &quot;keyToString&quot;: {
     &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,
     &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
-    &quot;last_opened_file_path&quot;: &quot;C:/Users/AZComputer/IdeaProjects/NTTData&quot;,
+    &quot;last_opened_file_path&quot;: &quot;C:/Users/AZComputer/IdeaProjects/Hive&quot;,
     &quot;settings.editor.selected.configurable&quot;: &quot;project.propVCSSupport.DirectoryMappings&quot;
   }
 }</component>
@@ -109,7 +84,14 @@
       <option name="project" value="LOCAL" />
       <updated>1665755781776</updated>
     </task>
-    <option name="localTasksCounter" value="2" />
+    <task id="LOCAL-00002" summary=" store the output in hdfs">
+      <created>1667980623897</created>
+      <option name="number" value="00002" />
+      <option name="presentableId" value="LOCAL-00002" />
+      <option name="project" value="LOCAL" />
+      <updated>1667980623898</updated>
+    </task>
+    <option name="localTasksCounter" value="3" />
     <servers />
   </component>
   <component name="Vcs.Log.Tabs.Properties">
@@ -149,6 +131,7 @@
       <path value="$PROJECT_DIR$" />
     </ignored-roots>
     <MESSAGE value="New jobs" />
-    <option name="LAST_COMMIT_MESSAGE" value="New jobs" />
+    <MESSAGE value=" store the output in hdfs" />
+    <option name="LAST_COMMIT_MESSAGE" value=" store the output in hdfs" />
   </component>
 </project>
\ No newline at end of file
Index: src/main/scala/org/data_training/jobs/Product_cat_ntt.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala b/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala
--- a/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala	
+++ b/src/main/scala/org/data_training/jobs/Product_cat_ntt.scala	
@@ -8,7 +8,7 @@
 case class Product_cat_ntt() extends Runnable {
   var product_Cat_ntDF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Product_cat_ntt JOB ##############")
 
     product_Cat_ntDF = spark.sql("SELECT * FROM product_category_name_translation ")
Index: src/main/scala/org/data_training/jobs/Order_reviews.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Order_reviews.scala b/src/main/scala/org/data_training/jobs/Order_reviews.scala
--- a/src/main/scala/org/data_training/jobs/Order_reviews.scala	
+++ b/src/main/scala/org/data_training/jobs/Order_reviews.scala	
@@ -9,7 +9,7 @@
 
   var order_reviews_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Order_reviews JOB ##############")
 
     order_reviews_DF = spark.sql("SELECT * FROM order_reviews_dataset ")
Index: src/main/scala/org/data_training/jobs/Order_items.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Order_items.scala b/src/main/scala/org/data_training/jobs/Order_items.scala
--- a/src/main/scala/org/data_training/jobs/Order_items.scala	
+++ b/src/main/scala/org/data_training/jobs/Order_items.scala	
@@ -9,7 +9,7 @@
 
   var order_items_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Order_items JOB ##############")
 
     order_items_DF = spark.sql("SELECT * FROM order_items_dataset ")
Index: src/main/scala/org/data_training/jobs/Geolocation.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Geolocation.scala b/src/main/scala/org/data_training/jobs/Geolocation.scala
--- a/src/main/scala/org/data_training/jobs/Geolocation.scala	
+++ b/src/main/scala/org/data_training/jobs/Geolocation.scala	
@@ -9,7 +9,7 @@
 
   var geolocation_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Geolocation JOB ##############")
 
     geolocation_DF = spark.sql("SELECT * FROM geolocation_dataset ")
Index: src/main/scala/org/data_training/jobs/Sellers.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/scala/org/data_training/jobs/Sellers.scala b/src/main/scala/org/data_training/jobs/Sellers.scala
--- a/src/main/scala/org/data_training/jobs/Sellers.scala	
+++ b/src/main/scala/org/data_training/jobs/Sellers.scala	
@@ -9,7 +9,7 @@
 
   var sellers_DF: DataFrame = _
 
-  def run(spark: SparkSession, odate: String, engine: Engine): Unit = {
+  def run(spark: SparkSession, odate: String, engine: Engine,args: String*): Unit = {
     print("############## starting Sellers JOB ##############")
 
     sellers_DF = spark.sql("SELECT * FROM sellers_dataset ")
